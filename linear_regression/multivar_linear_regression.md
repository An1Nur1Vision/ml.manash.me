# মাল্টিভ্যারিয়েবল লিনিয়ার রিগ্রেশন

গত পর্বগুলোতে আমরা দেখেছিলাম সিঙ্গেল ভ্যারিয়েবল বিশিষ্ট সমস্যাগুলোতে কীভাবে লিনিয়ার মডেল ফিট করতে হয়। আজকে আমরা দেখব, সমস্যাটি যদি মাল্টি ভ্যারিয়েবল \/ কলাম \/ ফিচার বিশিষ্ট হয় তাহলে তার অ্যানালাইসিসটা কেমন হবে।

## মাল্টিভ্যারিয়েবল বিশিষ্ট ডেটাসেট

কাজ শুরুর আগে ডেটাসেটটা একনজর দেখা যাক,

| Size \( $$feet^{2} $$ \) | Number of Bedrooms | Number of floors | Age of home \(years\) | Price \($1000\) |

| --- | --- | --- | --- | --- |

| 2104 | 5 | 1 | 45 | 460 |

| 1416 | 3 | 2 | 40 | 232 |

| 1534 | 3 | 2 | 30 | 315 |

| 852 | 2 | 1 | 36 | 178 |

## লক্ষণীয়

লক্ষ করলে দেখা যাবে, আগের মত ইনপুট ভ্যারিয়েবল আর একটা নাই। বরং অনেকগুলো, তারমানে এখন আর আমরা ফিচার শুধু $$x$$ ধরলেই হবে না। এখন আমাদের প্রতিটা কলাম ম্যাথেমেটিক্যাল নোটেশন দিয়ে আলাদা করতে হবে যেন আমরা বুঝতে পারি কোনটা আসলে কোন কলাম। এটা করার জন্য আমরা প্রতি কলামের জন্য $$ x $$ এর সাবস্ক্রিপ্ট দিয়ে কলাম নাম্বার বসাব। সুপারস্ক্রিপ্টে রো \(Row\) ইন্ডেক্স বসবে এবং সাবস্ক্রিপ্টে বসবে কলাম \(Column\) ইন্ডেক্স।

**উদাহরণ: \(শুধু প্রথম Row এর জন্য\)**

$$Size \; ( feet^{2} ) = x_{1}^{(1)}$$

$$Number \; of \; bedrooms = x_{2}^{(1)}$$

$$Number \; of \; floors = x_{3}^{(1)}$$

$$Age \; of \; home = x_{4}^{(1)}$$

$$Price = y_{1}^{(1)}$$

তাহলে $$ i $$ তম ইনপুট ভ্যারিয়েবল হবে $$ x_{i} $$ এবং $$ i $$ তম আউটপুট ভ্যারিয়েবল হবে $$ y_{i} $$

**২য় উদাহরণ**

আমরা যদি দ্বিতীয় সারির ইনপুট ভ্যারিয়েবলগুলোকে ম্যাট্রিক্সে সাজাতে চাই তাহলে সেটা হবে এইরকম, যেহেতু আমরা নির্দিষ্ট কোন Columwise ভ্যারিয়েবল বিবেচনা করছি না, সবগুলো ভ্যারিয়েবল নিয়ে একটি ম্যাট্রিক্স তৈরি করেছি তাই আমাদের আলাদা করে সাবস্ক্রিপ্ট বসানোর মানে নেই।

$$

X^{(2)} = \begin{bmatrix}  1416 \\ 3 \\ 2 \\ 40  \end{bmatrix}

$$

এবং দ্বিতীয় সারির আউটপুট হবে,

$$

Y^{(2)} = \begin{bmatrix} 232 \end{bmatrix}

$$

আশা করি তাহলে তৃতীয় ও চতুর্থ সারির ম্যাট্রিক্স নোটেশন কী হবে বুঝতে পেরেছেন। নোটেশন বোঝা শেষ, এবার আমরা সরাসরি চলে যাব মডেল বিল্ডিংয়ে।

### হাইপোথিসিস \(Hypothesis\)

আগের হাইপোথিসিস ছিল এটা,

$$

h_{\theta}(x) = \theta_{0} + \theta_{1}x

$$

এটা দিয়ে আমাদের এই মাল্টি ভ্যারিয়েবল সেটে কাজ করবে না। তাহলে উপায়? হুঁ, উপায় আছে, সেটা হল প্রতিটা ভ্যারিয়েবলের আগে একটা করে নতুন প্যারামিটার গুণ করে দেওয়া।

$$

h_{\theta}(x) = \theta_{0} + \theta_{1}x_{1} + \theta_{2}x_{2} + \theta_{3}x_{3} + \theta_{4}x_{4} \; ... (1)

$$

এখন আমরা থিটার বিভিন্ন মান ধরে ভালমন্দ প্রেডিকশন করতে পারব, যেমন,

$$

h_{\theta}(x) = 80 + 0.1x_{1} + 0.01x_{2} + 3x_{3} - 2x_{4} \; ... (2)

$$

এই সমীকরণ $$ (2) $$ সিরিয়াসলি নেয়ার কিছু নাই, এটা চিন্তাভাবনাহীন উদাহরণ।

## আবারও গণিত

ভয়ের কিছু নেই, আমরা এখানে বেসিক ম্যাথেমেটিক্যাল নোটেশন নিয়েই আলোচনা করতে বসেছি। কারণ নোটেশনগুলো বুঝলে General Purpose Machine Learning এর থিওরি বুঝতে সমস্যা হবে না, আমিও শর্টকাটে লিখতে পারব, আপনিও বুঝতে পারবেন।

### হাইপোথিসিস মডিফিকেশন

আমরা সমীকরণ $$ (1) $$ এ মাল্টিভ্যারিয়েবল হাইপোথিসিস মডেলটা দেখতে পাচ্ছি। কথা হল, আমরা যদি সেটাকে ম্যাট্রিক্স আকারে সাজাতে চাই তাহলে বিশাল একটা সমস্যায় পড়ব। কারণ, হাইপোথিসিস এর প্যারামিটার শুরু হয়েছে $$ \theta_{0} $$ থেকে, কিন্তু ভ্যারিয়েবলের রো শুরু হয়েছে $$ x_{1} $$ থেকে। তারমানে মডেল প্যারামিটারের সংখ্যা কলামের সংখ্যার চেয়ে বেশি। ম্যাট্রিক্সের যোগ বিয়োগ করতে হলে ডাইমেনশন সমান হতে হয়, ম্যাট্রিক্স অপারেশনগুলো কার্যকর করার জন্য তাই আমরা সমীকরণ $$ (1) $$ কে একটু মডিফাই করব।

আমরা সমীকরণ $$ (1) $$ কে লিখতে পারি এভাবে, $$ h_{\theta}(x) = \theta_{0}x_{0} + \theta_{1}x_{1} + \theta_{2}x_{2} + \theta_{3}x_{3} + \theta_{4}x_{4} + ... + \theta_{n}x_{n} \; ... (3) $$

যদি আমরা $$ x_{0} = 1 $$ ধরি তাহলে সমীকরণ $$ (2) $$ এবং $$ (3) $$ এর মধ্যে পার্থক্য থাকবে না।

আমরা $$ X $$ ও $$ \theta $$ কে যদি $$ n $$ সংখ্যক 

