প্র্যাক্টিক্যাল মাল্টিভ্যারিয়েবল লিনিয়ার রিগ্রেশন : গ্রেডিয়েন্ট ডিসেন্ট অ্যালগরিদমের রকমফের ও নরমাল রিপ্রেজেন্টেশন

গত পর্বে আমরা দেখেছিলাম সিঙ্গেল ভ্যারিয়েবল লিনিয়ার রিগ্রেশনের ফরমুলা ও পাইথনে ইম্প্লিমেন্টেশন। এই পর্বে দেখব মাল্টিভ্যারিয়েবল বা মাল্টিফিচার বিশিষ্ট রিগ্রেশন সমস্যা কীভাবে গ্রেডিয়েন্ট ডিসেন্ট অ্যালগরিদমের মাধ্যমে সল্ভ করে। তবে এখানে সিনথেটিক ডেটা দিয়ে সবকিছু আলোচনা করা হবে। সিনথেটিক ডেটা হল কোন ম্যাথেমেটিক্যাল ফরমুলা ব্যবহার করে জেনারেট করা ডেটা। আজকের আলোচ্য কন্টেন্ট দেখা যাক।

গ্রেডিয়েন্ট ডিসেন্টের প্রকারভেদ জানা খুবই দরকারী। প্রায় সময়ই ফাংশন অপ্টিমাইজেশনের ক্ষেত্রে এই কথাগুলো বেশি পরিমাণে ব্যবহৃত হয়। সাধারণত লিনিয়ার রিগ্রেশনের ক্ষেত্রে এদের ব্যবহার দেখানো হয় না, কিন্তু সিম্পল লিনিয়ার মডেল দিয়েই অ্যালগরিদমগুলো ভাল বোঝা যায় তাই এখানে আলোচনা করা হল। 

আলোচ্য বিষয়বস্তু:

- গ্রেডিয়েন্ট ডিসেন্ট ফরমুলা ডিরাইভ করা 
- সিনথেটিক ডেটা প্রস্তুত করা 
- ব্যাচ গ্রেডিয়েন্ট ডিসেন্ট (Batch Gradient Descent), স্টোক্যাস্টিক গ্রেডিয়েন্ট ডিসেন্ট (Stochastic Gradient Descent) ও মিনি-ব্যাচ গ্রেডিয়েন্ট ডিসেন্ট (Mini-batch Gradient Descent) এর সুবিধা-অসুবিধা ও পাইথনে ইম্প্লিমেন্টেশন
- গ্রেডিয়েন্ট ডিসেন্টের নরমাল রিপ্রেজেন্টেশন ফরমুলেশন, পাইথনে ইম্প্লিমেন্টেশন ও অসুবিধা
- গ্রেডিয়েন্ট ডিসেন্ট ম্যাট্রিক্স ফরমুলেশন ও পাইথনে ইম্প্লিমেন্টেশন 

লিনিয়ার রিগ্রেশনের জন্য গ্রেডিয়েন্ট ডিসেন্ট

গ্রেডিয়েন্ট ডিসেন্ট অ্যালগরিদম বলে, 


\theta_{j} := \theta_{j} -  \alpha \frac{\partial J(\theta)}{\partial \theta_{j}}


যেখানে,

- \theta হল প্যারামিটার
- j দিয়ে বুঝাচ্ছে কততম প্যারামিটার 
- \alpha হল লার্নিং রেট
- J(\theta) দিয়ে কস্ট ফাংশন বুঝানো হচ্ছে 


J(\theta) = \frac{1}{2m} \sum_{i=1}^{m}\big(h_{\theta}(x^{(i)})-y^{(i)}\big)^{2}


আবার যেখানে	

- m হচ্ছে রো সংখ্যা বা ডেটা কতগুলো আছে
- h_{\theta} হচ্ছে হাইপোথিসিস ফাংশন যেটা আমরা পরে ডিফাইন করব
- y^{(i)} হল ডেটাসেট এ দেয়া আউটপুট ভ্যালু 
- x^{(i)} হল ইনপুট ডেটা

গ্রেডিয়েন্ট ডিসেন্ট ফরমুলেশন

আগে দেখানো হয়েছিল কীভাবে ম্যাট্রিক্সে কস্ট ক্যালকুলেট করে কিন্তু গ্রেডিয়েন্ট ডিসেন্ট অ্যালগরিদমে কস্ট ফাংশনকে ডেরিভেটিভ করলে কী আসে সেটা দেখানো হয় নি। শুরু করা যাক। 

লিনিয়ার রিগ্রেশনের হাইপোথিসিস সাধারণত এরকম হয়, 


h_{\theta}(X) = \theta_{0}x_{0} + \theta_{1}x_{1}+\theta_{2}x_{2}


যেখানে, 


X = \begin{bmatrix} x_{0}=1 \\ x_{1} \\ x_{2} \end{bmatrix}


যদি ইনপুটের ফিচার বা কলাম সংখ্যা হয় দুইটা। ডেটাসেট এ দুইটা ফিচার থাকলেও আমরা একস্ট্রা একটা কলাম 1 সেট করে নেব। ম্যাট্রিক্সে ফরমুলেট করার জন্য এই 1 এর গুরুত্ব অপরিসীম। 

আমরা হাইপোথিসিস ফাংশনকে এভাবে আরও সংক্ষিপ্ত আকারে লিখতে পারি, 

 h_{\theta}(X) = \sum_{i=0}^{n}\theta_{i}x_{i} 

ম্যাট্রিক্স আকারে, 

h_{\theta}(X) = \theta^{T}X

বিখ্যাত ডেটাসেটটা আবার আনি, 

  বাড়ির আকার ( x_{1}) (sq-ft)	ঘর সংখ্যা (x_{2})	বাড়ির দাম  y  (lac)
  1200                       	5                	120                
  1300                       	6                	125                
  1400                       	7                	130                

এখানে, m=3 কারণ Row মাত্র তিনটা। এবং ফিচার দুইটা x_{1}, x_{2}  । যেহেতু x_{0} সহ তিনটা তাই n=3  

ডেটাসেট পাওয়ার পরে আমরা একস্ট্রা একটা ফিচার কলাম জুড়ে দিলে হবে এরকম, 

  x_{0}	বাড়ির আকার ( x_{1}) (sq-ft)	ঘর সংখ্যা (x_{2})	বাড়ির দাম  y  (lac)
  1    	1200                       	5                	120                
  1    	1300                       	6                	125                
  1    	1400                       	7                	130                

\theta_{j} := \theta_{j} - \alpha \frac{\partial J(\theta)}{\partial \theta_{j}}  

এই ফরমুলাতে আমাদের আগে বের করতে হবে,  \frac{\partial J(\theta)}{\partial \theta_{j}} এটার মান কত। এটার মান বের করতে পারলে তারপর অ্যালগরিদমে বসিয়ে দিলেই হবে। 


\begin{align}
\frac{\partial J(\theta)}{\partial \theta_{j}} &= \frac{\partial}{\partial \theta_{j}} \frac{1}{2} \big(h_{\theta}(x) - y \big)^{2} \\ 
&= 2 \times \frac{1}{2} \big(h_{\theta}(x) - y \big) \times \frac{\partial}{\partial \theta_{j} } \big(h_{\theta}(x) - y \big) \\
&= \big(h_{\theta}(x) - y \big) \times  \frac{\partial}{\partial \theta_{j} } \left( \sum_{i=0}^{n}\theta_{i}x_{i} - y  \right) \\
&= (h_{\theta}(x) - y \big) \times \sum_{j=1}^{m} \frac{\partial}{\partial \theta_{j} } \left( \theta_{j}x_{j} \right) - 
\end{align}



